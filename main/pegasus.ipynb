{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9281e91",
   "metadata": {},
   "source": [
    "# Transformer Model - PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cf9ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers[torch] datasets rouge-score nltk sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d533ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    PegasusForConditionalGeneration, PegasusTokenizer,\n",
    "    Trainer, TrainingArguments,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af52062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for reproducability\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fb0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab954d",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f740fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Pegasus Model\n",
    "\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3549ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusForConditionalGeneration(\n",
       "  (model): PegasusModel(\n",
       "    (shared): Embedding(96103, 1024, padding_idx=0)\n",
       "    (encoder): PegasusEncoder(\n",
       "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x PegasusEncoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): PegasusDecoder(\n",
       "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x PegasusDecoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd789b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f94b74",
   "metadata": {},
   "source": [
    "## Load Dataset and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, val and test data\n",
    "\n",
    "train_data = pd.read_csv('../data/pubmed_dataset_preprocessed/train.csv')\n",
    "val_data = pd.read_csv('../data/pubmed_dataset_preprocessed/val.csv')\n",
    "test_data = pd.read_csv('../data/pubmed_dataset_preprocessed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb17d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "# custom Dataset class\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        article = self.data.iloc[idx]['article']\n",
    "        abstract = self.data.iloc[idx]['abstract']\n",
    "        \n",
    "        # tokenize article and abstract\n",
    "        input_encoding = self.tokenizer(\n",
    "            article,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        output_encoding = self.tokenizer(\n",
    "            abstract,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = input_encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = input_encoding['attention_mask'].squeeze(0)\n",
    "        \n",
    "        output_ids = output_encoding['input_ids'].squeeze(0)  # Same here\n",
    "        output_attention_mask = output_encoding['attention_mask'].squeeze(0)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': output_ids,\n",
    "            'output_attention_mask': output_attention_mask\n",
    "        }\n",
    "\n",
    "# dataset\n",
    "train_dataset = TokenizedDataset(train_data, tokenizer, max_length=tokenizer.model_max_length)\n",
    "val_dataset = TokenizedDataset(val_data, tokenizer, max_length=tokenizer.model_max_length)\n",
    "test_dataset = TokenizedDataset(test_data, tokenizer, max_length=tokenizer.model_max_length)\n",
    "\n",
    "# dataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2871be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  126,  4403,   115,  ...,   164,   233,     1],\n",
      "        [15962, 39237, 35368,  ...,  1532,   196,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[ 1688, 32680,   115,  ...,     0,     0,     0],\n",
      "        [15962, 39237, 35368,  ...,     0,     0,     0]]), 'output_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34546ec",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9aa1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to finetune model\n",
    "\n",
    "def finetune_model(model, train_dataloader, val_dataloader, tokenizer, \n",
    "                num_epochs=3, learning_rate=2e-5, warmup_steps=500, \n",
    "                checkpoint_path='../models/best_checkpoint.pt'):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # scheduler\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # mixed precision (speed up training)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            logger.info(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "            # training loop\n",
    "            model.train()\n",
    "            epoch_train_loss = 0\n",
    "            train_progress = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "            for batch in train_progress:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                # backpropagation\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # update weights (and scheduler)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "\n",
    "                epoch_train_loss += loss.item()\n",
    "                train_progress.set_postfix({'batch_loss': loss.item()})\n",
    "\n",
    "                # clear memory\n",
    "                del outputs, loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            avg_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            logger.info(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "            # val loop\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0\n",
    "            val_progress = tqdm(val_dataloader, desc=\"Validation\", leave=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in val_progress:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "\n",
    "                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                        loss = outputs.loss\n",
    "\n",
    "                    epoch_val_loss += loss.item()\n",
    "                    val_progress.set_postfix({'batch_loss': loss.item()})\n",
    "\n",
    "                    del outputs, loss\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            avg_val_loss = epoch_val_loss / len(val_dataloader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            logger.info(f\"Average validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # checkpoint best model\n",
    "#             if avg_val_loss < best_val_loss:\n",
    "#                 best_val_loss = avg_val_loss\n",
    "#                 torch.save(model.state_dict(), checkpoint_path)\n",
    "#                 logger.info(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        # load best model weights before returning\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Training interrupted. Returning current model state.\")\n",
    "\n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a124a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder to save models\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20af1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model, train_loss, val_loss = finetune_model(model, train_loader, val_loader, tokenizer, \n",
    "                num_epochs=3, learning_rate=2e-5, warmup_steps=500, \n",
    "                checkpoint_path='../models/pegasus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f45eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot training and validation loss\n",
    "\n",
    "def plot_loss_curves(train_losses, val_losses, title=\"Loss Curves\"):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    plt.plot(train_losses, label='Training Loss', color='blue', linestyle='-', linewidth=2)\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf353eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e364777",
   "metadata": {},
   "source": [
    "## ROUGE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate model (rouge scores)\n",
    "\n",
    "def evaluate_model(model, test_dataloader, tokenizer, max_length=512, num_beams=4):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Generate summaries\n",
    "            summary_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length,\n",
    "                num_beams=num_beams,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "            \n",
    "            # Decode predictions\n",
    "            decoded_preds = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "            decoded_refs = [tokenizer.decode(g, skip_special_tokens=True) for g in batch['labels']]\n",
    "            \n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_refs)\n",
    "        \n",
    "        # Clear GPU memory after all batches\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': [], 'rougeLsum': []}\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = rouge.score(ref, pred)\n",
    "        for key in scores:\n",
    "            scores[key].append(score[key].fmeasure)\n",
    "    \n",
    "    # Average ROUGE scores\n",
    "    avg_scores = {key: np.mean(values) for key, values in scores.items()}\n",
    "    \n",
    "    return scores, avg_scores, predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, avg_scores, predictions, references = evaluate_model(finetuned_model, test_loader, tokenizer, \n",
    "                                                     max_length=tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ce0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge scores\n",
    "\n",
    "for metric, score in avg_scores.items():\n",
    "        print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#         'article': test_data['article'],\n",
    "#         'reference': test_data['abstract'],\n",
    "#         'prediction': predictions\n",
    "#     })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
